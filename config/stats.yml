#!/usr/bin/env python3
# -*- coding:utf-8 -*-
# ================================================================================================ #
# Project    : Artificial Intelligence & Data Science Studio                                       #
# Version    : 0.1.0                                                                               #
# Python     : 3.10.12                                                                             #
# Filename   : /config/stats.yml                                                                   #
# ------------------------------------------------------------------------------------------------ #
# Author     : John James                                                                          #
# Email      : john.james.ai.studio@gmail.com                                                      #
# URL        : https://github.com/john-james-ai/studioai                                           #
# ------------------------------------------------------------------------------------------------ #
# Created    : Tuesday August 22nd 2023 06:15:35 pm                                                #
# Modified   : Tuesday August 22nd 2023 06:16:02 pm                                                #
# ------------------------------------------------------------------------------------------------ #
# License    : MIT License                                                                         #
# Copyright  : (c) 2023 John James                                                                 #
# ================================================================================================ #
ad:
  '#': 13
  H0: Data drawn from stated distribution family
  Version: 2
  analysis: univariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: .nan
  description: 'The Anderson-Darling test tests the null hypothesis that a sample
    is drawn from a population that follows a particular distribution. For the Anderson-Darling
    test, the critical values depend on which distribution is being tested against.
    This function works for normal, exponential, logistic, or Gumbel (Extreme Value
    Type I) distributions.


    '
  function: scipy.stats.goodness_of_fit
  hypothesis: Goodness of Fit
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.goodness_of_fit.html#scipy.stats.goodness_of_fit
  min_sample_size: 20
  name: Anderson-Darling Test
  package: Scipy
  parametric: false
  small_sample_sizes: true
  statistic: A2
  status: Pending
  use_when: More powerful in fatty tails, e.g. financial analysis
  x_variable_type: continuous
  y_variable_type: .nan
anova1:
  '#': 7
  H0: Means are the same
  Version: 1
  analysis: univariate
  assumes_homoscedasticity: true
  assumes_normality: true
  assumptions: '

    1. Response variable residuals are normally distributed (or approximately normally
    distributed).

    2. Variances of populations are equal.

    3. Responses for a given group are independent and identically distributed normal
    random variables (not a simple random sample (SRS)).


    '
  description: 'Perform one-way ANOVA.


    The one-way ANOVA tests the null hypothesis that two or more groups have the same
    population mean. The test is applied to samples from two or more groups, possibly
    with differing sizes.


    '
  function: scipy.stats.f_oneway
  hypothesis: Centrality
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html
  min_sample_size: 30
  name: Anova (One-Way)
  package: Scipy
  parametric: true
  small_sample_sizes: true
  statistic: ANOVA F
  status: Pending
  use_when: When the number of groups to compare > 2
  x_variable_type: continuous
  y_variable_type: .nan
fisher:
  '#': 5
  H0: The relative proportions of one variable are independent of the second variable;
    in other words, the proportions at one variable are the same for different values
    of the second variable
  Version: 2
  analysis: bivariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: '

    1: The row and column totals are fixed, not random.

    2. Sampling or allocation are random and observations are mutually independent
    within the constraints of fixed marginal totals.

    3. Each observation is mutually exclusive - in other words each observation can
    only be classified in one cell.


    '
  description: "Perform a Fisher exact test on a 2x2 contingency table.\n\nThe null\
    \ hypothesis is that the true odds ratio of the populations underlying the observations\
    \ is one, and the observations were sampled from these populations under a condition:\
    \ the marginals of the resulting table must equal those of the observed table.\
    \ The statistic returned is the unconditional maximum likelihood estimate of the\
    \ odds ratio, and the p-value is the probability under the null hypothesis of\
    \ obtaining a table at least as extreme as the one that was actually observed.\
    \ There are other possible choices of statistic and two-sided p-value definition\
    \ associated with Fisher\u2019s exact test; please see the Notes for more information.\n\
    \n"
  function: scipy.stats.fisher_exact
  hypothesis: Independence of Two Variables
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.fisher_exact.html#scipy.stats.fisher_exact
  min_sample_size: 30
  name: Fisher's Exact Test
  package: Scipy
  parametric: false
  small_sample_sizes: true
  statistic: .nan
  status: Pending
  use_when: Small Sample Sizes, or expected cell size < 5
  x_variable_type: nominal
  y_variable_type: nominal
ks1:
  '#': 3
  H0: Data drawn from the reference distribution
  Version: 1
  analysis: univariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: '

    1. The two samples are mutually independent.

    2. The scale of measurement is at least ordinal.

    3. The test is only exact for continuous variables.


    '
  description: 'Perform a goodness of fit test comparing data to a distribution family.


    Given a distribution family and data, perform a test of the null hypothesis that
    the data were drawn from a distribution in that family. Any known parameters of
    the distribution may be specified. Remaining parameters of the distribution will
    be fit to the data, and the p-value of the test is computed accordingly. Several
    statistics for comparing the distribution to data are available.'
  function: scipy.stats.goodness_of_fit
  hypothesis: Goodness of Fit
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.goodness_of_fit.html#scipy.stats.goodness_of_fit
  min_sample_size: 50
  name: Kolmogorov-Smirnov Test
  package: Scipy
  parametric: false
  small_sample_sizes: false
  statistic: "Kolmogorov\u2013Smirnov "
  status: Done
  use_when: Large samples sizes > 50
  x_variable_type: continuous
  y_variable_type: .nan
kstest:
  '#': 3
  H0: Data drawn from the same distribution
  Version: 1
  analysis: univariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: '

    1. The two samples are mutually independent.

    2. The scale of measurement is at least ordinal.

    3. The test is only exact for continuous variables.


    '
  description: 'Performs the (one-sample or two-sample) Kolmogorov-Smirnov test for
    goodness of fit.


    The one-sample test compares the underlying distribution F(x) of a sample against
    a given distribution G(x). The two-sample test compares the underlying distributions
    of two independent samples. Both tests are valid only for continuous distributions.


    '
  function: scipy.stats.kstest
  hypothesis: Goodness of Fit
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html#scipy.stats.kstest
  min_sample_size: 50
  name: Kolmogorov-Smirnov Test
  package: Scipy
  parametric: false
  small_sample_sizes: false
  statistic: "Kolmogorov\u2013Smirnov "
  status: Done
  use_when: Large samples sizes > 50
  x_variable_type: continuous
  y_variable_type: continuous
kw:
  '#': 11
  H0: Variances of groups are the same
  Version: 1
  analysis: univariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: '

    1. Samples are random samples, or allocation to treatment group is random.

    2. The two samples are mutually independent.

    3. The measurement scale is at least ordinal, and the variable is continuous.


    '
  description: 'The Kruskal-Wallis H-test tests the null hypothesis that the population
    median of all of the groups are equal. It is a non-parametric version of ANOVA.
    The test works on 2 or more independent samples, which may have different sizes.
    Note that rejecting the null hypothesis does not indicate which of the groups
    differs. Post hoc comparisons between groups are required to determine which groups
    are different.


    '
  function: scipy.stats.kruskal
  hypothesis: Centrality
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html#scipy.stats.kruskal
  min_sample_size: 30
  name: "Kruskal\u2013Wallis Test"
  package: Scipy
  parametric: false
  small_sample_sizes: true
  statistic: "Kruskal\u2013Wallis H"
  status: Pending
  use_when: Assumptions of ANOVA are not met.
  x_variable_type: continuous
  y_variable_type: continuous
mwu:
  '#': 10
  H0: Distributions are the same
  Version: 1
  analysis: univariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: '

    1. All the observations from both groups are independent of each other,

    2. The responses are at least ordinal (i.e., one can at least say, of any two
    observations, which is the greater),


    '
  description: 'Perform the Mann-Whitney U rank test on two independent samples.


    The Mann-Whitney U test is a nonparametric test of the null hypothesis that the
    distribution underlying sample x is the same as the distribution underlying sample
    y. It is often used as a test of difference in location between distributions.


    '
  function: scipy.stats.mannwhitneyu
  hypothesis: Centrality
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html#scipy.stats.mannwhitneyu
  min_sample_size: 5
  name: Mann-Whitney U Rank Test
  package: Scipy
  parametric: false
  small_sample_sizes: true
  statistic: Mann-Whitney U
  status: Pending
  use_when: Data are non-normal
  x_variable_type: continuous
  y_variable_type: continuous
pearson:
  '#': 14
  H0: Distributions are uncorrelated
  Version: 2
  analysis: bivariate
  assumes_homoscedasticity: false
  assumes_normality: true
  assumptions: '

    1. Both variables are continuous

    2. Both variables are normally distributed

    3. Linear relationship between the two variables.

    4. Data are homoscedastic.


    '
  description: 'The Pearson correlation coefficient [1] measures the linear relationship
    between two datasets. Like other correlation coefficients, this one varies between
    -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact
    linear relationship. Positive correlations imply that as x increases, so does
    y. Negative correlations imply that as x increases, y decreases.


    This function also performs a test of the null hypothesis that the distributions
    underlying the samples are uncorrelated and normally distributed. (See Kowalski
    [3] for a discussion of the effects of non-normality of the input on the distribution
    of the correlation coefficient.) The p-value roughly indicates the probability
    of an uncorrelated system producing datasets that have a Pearson correlation at
    least as extreme as the one computed from these datasets.


    '
  function: scipy.stats.pearsonr
  hypothesis: Correlation of Two Variables
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr
  min_sample_size: 25
  name: Pearson's Correlation Test
  package: Scipy
  parametric: true
  small_sample_sizes: true
  statistic: Pearson product-moment correlation coefficient
  status: Done
  use_when: Variables are normally distributed and linearly related.
  x_variable_type: continuous
  y_variable_type: continuous
spearman:
  '#': 15
  H0: Distributions are uncorrelated
  Version: 2
  analysis: bivariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: "\n1: Two variables should be measured on an ordinal, interval or ratio\
    \ scale. \n2. Two variables represent paired observations.\n3. There is a monotonic\
    \ relationship between the two variables.\n\n"
  description: 'Calculate a Spearman correlation coefficient with associated p-value.


    The Spearman rank-order correlation coefficient is a nonparametric measure of
    the monotonicity of the relationship between two datasets. Like other correlation
    coefficients, this one varies between -1 and +1 with 0 implying no correlation.
    Correlations of -1 or +1 imply an exact monotonic relationship. Positive correlations
    imply that as x increases, so does y. Negative correlations imply that as x increases,
    y decreases.


    The p-value roughly indicates the probability of an uncorrelated system producing
    datasets that have a Spearman correlation at least as extreme as the one computed
    from these datasets. Although calculation of the p-value does not make strong
    assumptions about the distributions underlying the samples, it is only accurate
    for very large samples (>500 observations). For smaller sample sizes, consider
    a permutation test (see Examples section below).


    '
  function: scipy.stats.spearmanr
  hypothesis: Correlation of Two Variables
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html#scipy.stats.spearmanr
  min_sample_size: 15
  name: Spearman's Correlation Test
  package: Scipy
  parametric: false
  small_sample_sizes: true
  statistic: "Spearman\u2019s rho (S)"
  status: Done
  use_when: Assumptions of Pearson's Correlation are not met or data are ordinal.
  x_variable_type: continuous
  y_variable_type: continuous
sw:
  '#': 12
  H0: Samples drawn from normal distribution
  Version: 1
  analysis: univariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: .nan
  description: 'The Shapiro-Wilk test tests the null hypothesis that the data was
    drawn from a normal distribution.


    '
  function: scipy.stats.shapiro
  hypothesis: Normality
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html#scipy.stats.shapiro
  min_sample_size: 30
  name: Shapiro-Wilk Test
  package: Scipy
  parametric: false
  small_sample_sizes: true
  statistic: Shapiro-Wilk W
  status: Done
  use_when: Sample sizes < 50
  x_variable_type: continuous
  y_variable_type: .nan
t2:
  '#': 6
  H0: The means of two independent samples, drawn from a normal distribution, with
    equal variances, are identical.
  Version: 1
  analysis: univariate
  assumes_homoscedasticity: false
  assumes_normality: true
  assumptions: '

    1. The two samples are mutually independent.

    2. Two samples follow normal distributions.


    '
  description: 'Calculate the T-test for the means of two independent samples of scores.


    This is a test for the null hypothesis that 2 independent samples have identical
    average (expected) values. This test assumes that the populations have identical
    variances by default.


    '
  function: scipy.stats.ttest_ind
  hypothesis: Centrality
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind
  min_sample_size: 30
  name: T-test - Independent Samples
  package: Scipy
  parametric: true
  small_sample_sizes: true
  statistic: T
  status: Done
  use_when: Data are normally distributed
  x_variable_type: continuous
  y_variable_type: continuous
x2gof:
  '#': 2
  H0: Categorical data have the given frequencies
  Version: 1
  analysis: univariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: '


    1. Data values that are a simple random sample from the full population.

    2. Categorical or nominal data.

    3. A data set that is large enough so that at least five values are expected in
    each of the observed data categories.


    '
  description: 'Calculate a one-way chi-square test.


    The chi-square test tests the null hypothesis that the categorical data has the
    given frequencies.


    '
  function: scipy.stats.chisquare
  hypothesis: Goodness of Fit
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html#scipy.stats.chisquare
  min_sample_size: 50
  name: Chi-Square Test of Goodness of Fit
  package: Scipy
  parametric: false
  small_sample_sizes: false
  statistic: X2
  status: Done
  use_when: Expected frequency for all cells is > 5
  x_variable_type: nominal
  y_variable_type: .nan
x2ind:
  '#': 4
  H0: Two or more categorical variables are independent
  Version: 2
  analysis: bivariate
  assumes_homoscedasticity: false
  assumes_normality: false
  assumptions: '

    1: Both variables are categorical.

    2: All observations are independent.

    3: Cells in the contingency table are mutually exclusive.

    4: Expected value of cells should be 5 or greater in at least 80% of cells.


    '
  description: 'Chi-square test of independence of variables in a contingency table.


    This function computes the chi-square statistic and p-value for the hypothesis
    test of independence of the observed frequencies in the contingency table [1]
    observed. The expected frequencies are computed based on the marginal sums under
    the assumption of independence; see scipy.stats.contingency.expected_freq. The
    number of degrees of freedom is (expressed using numpy functions and attributes)


    '
  function: scipy.stats.chi2_contingency
  hypothesis: Independence of Two Variables
  link: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html
  min_sample_size: 1000
  name: Chi-Square of Independence
  package: Scipy
  parametric: false
  small_sample_sizes: false
  statistic: X2
  status: Done
  use_when: Two groups with dichotomous dependent variable.
  x_variable_type: nominal
  y_variable_type: nominal
